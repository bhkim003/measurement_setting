{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능 여부: True\n",
      "현재 장치 인덱스: 0\n",
      "사용 중인 GPU 모델: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "CUDA 연산 능력(Compute Capability): (8, 9)\n",
      "총 GPU 메모리: 8188 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. CUDA(GPU) 사용 가능 여부 확인\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"GPU 사용 가능 여부: {is_cuda}\")\n",
    "\n",
    "if is_cuda:\n",
    "    # 2. 현재 사용 중인 GPU 장치 인덱스\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"현재 장치 인덱스: {current_device}\")\n",
    "    \n",
    "    # 3. 그래픽카드 모델명 확인 (RTX 4070이 나와야 합니다)\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"사용 중인 GPU 모델: {device_name}\")\n",
    "    \n",
    "    # 4. GPU 사양 및 메모리 확인\n",
    "    capability = torch.cuda.get_device_capability(current_device)\n",
    "    print(f\"CUDA 연산 능력(Compute Capability): {capability}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_centralized_memory_info(current_device)[0] if hasattr(torch.cuda, 'get_centralized_memory_info') else torch.cuda.get_device_properties(current_device).total_memory\n",
    "    print(f\"총 GPU 메모리: {total_memory / 1024**2:.0f} MB\")\n",
    "else:\n",
    "    print(\"GPU를 찾을 수 없습니다. CPU 모드로 작동합니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
